import { NextRequest } from "next/server";
import OpenAI from "openai";
const vectorStoreId = process.env.VECTOR_STORE_ID || "";
const openai = new OpenAI();

export async function POST(req: NextRequest) {
  const { messages } = await req.json(); // [{role:"user", content:"â€¦"}]

  const res = await openai.responses.create({
    model: "gpt-4o-mini",
    tools: [{ type: "file_search", vector_store_ids: [vectorStoreId] }],
    include: ["file_search_call.results"],
    input: [
      {
        type: "message",
        role: "system",
        content:
          `ã‚ãªãŸã¯ãƒ†ãƒ¼ãƒ©ãƒ¯ãƒ¼ãƒ€ä»æ•™ã®å°‚é–€å®¶ã§ã™ã€‚
          å›žç­”ã¯å¿…ãšãƒ†ãƒ¼ãƒ©ãƒ¯ãƒ¼ãƒ€ä»æ•™ã®æ•™ç¾©ã«åŸºã¥ã„ã¦è¡Œã†ã“ã¨ã€‚
          ã¾ãŸã€å›žç­”ã¯å¿…ãšæ—¥æœ¬èªžã§ã€è³ªå•ã«ç«¯çš„ã«ç­”ãˆã¦ãã ã•ã„ã€‚
          è³ªå•è€…ãŒè§£è„±ã¸ã¨è¿‘ã¥ãã‚ˆã†ã«ã€è³ªå•ã«å¯¾ã™ã‚‹å›žç­”ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚`
      },
      ...messages.map((m: any) => ({
        type: "message",
        role: m.role,
        content: m.content
      }))
    ]
  });
  const citationBlocks: string[] = [];

  for (const item of res.output ?? []) {
    if (item.type === "file_search_call" && item.results) {
      for (const r of item.results) {
        citationBlocks.push(
          `- **${r.filename ?? r.file_id}**\n  > ${r.text?.trim()}`
        );
      }
    }
  }

  const answer = citationBlocks.length
    ? `${res.output_text.trim()}

---

<details>
<summary>ðŸ“š å‡ºå…¸</summary>

${citationBlocks.join("\n\n")}

</details>`
    : res.output_text;
  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

  return new Response(answer, {
    headers: { "Content-Type": "text/markdown; charset=utf-8" }
  });

}
